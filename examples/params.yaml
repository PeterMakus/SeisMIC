#### Project wide parameters
# lowest level project directory
proj_dir : 'data'
# directory for logging information
log_subdir : 'log'
# levels:
# 'DEBUG', 'INFO', 'WARNING', 'ERROR', or 'CRITICAL'
log_level: 'WARNING'
# folder for figures
fig_subdir : 'figures'


#### parameters that are network specific
net:
    # list of stations used in the project
    # type: list of strings or string, wildcards allowed
    network : 'X9'
    station : 'IR1'

#### parameters for correlation (emperical Green's function creation)
co:
    # subdirectory of 'proj_dir' to store correlation
    # type: string
    subdir : 'corr'
    # times sequences to read for cliping or muting on stream basis
    # These should be long enough for the reference (e.g. the standard
    # deviation) to be rather independent of the parts to remove
    # type: string
    read_start : '2016-01-25 00:00:01.0'
    read_end : '2016-02-05 00:00:00.0'
    # type: float [seconds]
    # The longer the faster, but higher RAM usage.
    # Note that this is also the length of the correlation batches
    # that will be written (i.e., length that will be 
    # kept in memory before writing to disk)
    read_len : 86398
    read_inc : 86400

    # New sampling rate in Hz. Note that it will try to decimate
    # if possible (i.e., there is an integer factor from the
    # native sampling_rate)
    sampling_rate : 10
    # Remove the instrument response, will take substantially more time
    remove_response : True

    # Method to combine different traces
    combination_method : 'autoComponents'
  
    # If you want only specific combinations to be computed enter them here
    # In the form [Net0-Net0.Stat0-Stat1]
    # This option will only be consider if combination_method == 'betweenStations'
    # Comment or set == None if not in use
    xcombinations : None

    # preprocessing of the original length time series
    # these function work on an obspy.Stream object given as first argument
    # and return an obspy.Stream object.
    preProcessing : [
                    {'function':'seismic.correlate.preprocessing_stream.detrend_st',
                    'args':{'type':'linear'}},
                    {'function':'seismic.correlate.preprocessing_stream.cos_taper_st',
                      'args':{'taper_len': 100, # seconds
                              'lossless': True}}, # lossless tapering stitches additional data to trace, tapers, and removes the tapered ends after preprocessing
                    {'function':'seismic.correlate.preprocessing_stream.stream_filter',
                      'args':{'ftype':'bandpass',
                              'filter_option':{'freqmin':0.01, #0.01
                                               'freqmax':4.9}}}
                     #{'function':'seismic.correlate.preprocessing_stream.stream_mute',
                     # 'args':{'taper_len':100,
                     #         'mute_method':'std_factor',
                     #         'mute_value':3}}
                    ]
    # subdivision of the read sequences for correlation
    # if this is set the stream processing will happen on the hourly subdivision. This has the
    # advantage that data that already exists will not need to be preprocessed again
    # On the other hand, computing a whole new database might be slower
    # Recommended to be set to True if:
    # a) You update your database and a lot of the data is already available (up to a magnitude faster)
    # b) corr_len is close to read_len
    # Is automatically set to False if you are computing a completely new db
    preprocess_subdiv: True
    # type: presence of this key
    subdivision:
        # type: float [seconds]
        corr_inc : 3600
        corr_len : 3600
        # recombine these subdivisions
        # unused at the time
        # type: boolean
        recombine_subdivision : True
        # delete
        # type: booblean
        delete_subdivision : False

    # parameters for correlation preprocessing
    # Standard functions reside in seismic.correlate.preprocessing_td and preprocessing_fd, respectively
    corr_args : {'TDpreProcessing':[
                                    # detrend not recommended. Use preProcessing detrend_st instead (faster)
                                    # {'function':'seismic.correlate.preprocessing_td.detrend',
                                    # 'args':{'type':'linear'}},
                                   {'function':'seismic.correlate.preprocessing_td.TDfilter',
                                   'args':{'type':'bandpass','freqmin':2,'freqmax':4}},
                                    #{'function':'seismic.correlate.preprocessing_td.mute',
                                    # 'args':{'taper_len':100.,
                                           # 'threshold':1000, absolute threshold
                                    #         'std_factor':3,
                                    #         'filter':{'type':'bandpass','freqmin':2,'freqmax':4},
                                    #         'extend_gaps':True}},
                                  #  {'function':'seismic.correlate.preprocessing_td.clip',
                                  #   'args':{'std_factor':2.5}},
                                   {'function':'seismic.correlate.preprocessing_td.signBitNormalization',
                                    'args': {}}
                                   ],
                  # Standard functions reside in seismic.correlate.preprocessing_fd
                 'FDpreProcessing':[
                                    # {'function':'seismic.correlate.preprocessing_fd.spectralWhitening',
                                    #  'args':{'joint_norm':False}},
                                    {'function':'seismic.correlate.preprocessing_fd.FDfilter',
                                     'args':{'flimit':[1.5,2,4,5]}}
                                    #  {'function':seismic.correlate.preprocessing_fd.FDsignBitNormalization,
                                    # 'args':{}}
                                    ],
                 'lengthToSave':20,
                 'center_correlation':True,      # make sure zero correlation time is in the center
                 'normalize_correlation':True,
                 'combinations':[]
                }


#### parameters for the estimation of time differences
dv:
    # subfolder for storage of time difference results
    subdir : 'vel_change'

    # Plotting
    plot_vel_change : True

    ### Definition of calender time windows for the time difference measurements
    start_date : '2016-01-25 00:00:00.0'   # %Y-%m-%dT%H:%M:%S.%fZ'
    end_date : '2016-02-05 00:00:00.0'
    win_len : 3600                         # length of window in which EGFs are stacked
    date_inc : 3600                        # increment of measurements

    ### Frequencies
    freq_min : 2
    freq_max : 4

    ### Definition of lapse time window
    tw_start : 3.5     # lapse time of first sample [s]
    tw_len : 8.5       # length of window [s] Can be None if the whole (rest) of the coda should be used
    sides : 'both'   # options are left (for acausal), right (causal), both, or single (for active source experiments where the first sample is the trigger time)
    compute_tt : True  # Computes the travel time and adds it to tw_start (tt is 0 if not xstations). If true a rayleigh wave velocity has to be provided
    rayleigh_wave_velocity : 1  # rayleigh wave velocity in km/s, will be ignored if compute_tt=False
    

    ### Range to try stretching
    stretch_range : 0.03
    stretch_steps : 1001
  
    #### Reference trace extraction
    #  win_inc : Length in days of each reference time window to be used for trace extraction
    # If == 0, only one trace will be extracted
    # If > 0, mutliple reference traces will be used for the dv calculation
    # Can also be a list if the length of the windows should vary
    # See seismic.correlate.stream.CorrBulk.extract_multi_trace for details on arguments
    dt_ref : {'win_inc' : 0, 'method': 'mean', 'percentile': 50}

    # preprocessing on the correlation bulk or corr_stream before stretch estimation
    preprocessing: [
                    #{'function': 'pop_at_utcs', 'args': {'utcs': np.array([UTCDateTime()])},
                    {'function': 'smooth', 'args': {'wsize': 4, 'wtype': 'hanning', 'axis': 1}}
    ]

    # postprocessing of dv objects before saving and plotting
    postprocessing: [
                      # {'function': 'smooth_sim_mat', 'args': {'win_len': 7, exclude_corr_below: 0}}
    ]

#### parameters to compute the waveform coherence
wfc:
  # subfolder for storage of time difference results
    subdir : 'wfc'

    ### Definition of calender time windows for the time difference measurements
    start_date : '2015-05-01 00:00:00.0'   # %Y-%m-%dT%H:%M:%S.%fZ'
    end_date : '2016-01-01 00:00:00.0'
    win_len : 86400                         # length of window in which EGFs are stacked
    date_inc : 86400                        # increment of measurements

    ### Frequencies
    freq_min : 4
    freq_max : 8

    ### Definition of lapse time window
    tw_start : 20     # lapse time of first sample [s]
    tw_len : 60       # length of window [s]
  
    #### Reference trace extraction
    #  win_inc : Length in days of each reference time window to be used for trace extraction
    # If == 0, only one trace will be extracted
    # If > 0, mutliple reference traces will be used for the dv calculation
    # Can also be a list if the length of the windows should vary
    # See seismic.correlate.stream.CorrBulk.extract_multi_trace for details on arguments
    dt_ref : {'win_inc' : 0, 'method': 'mean', 'percentile': 50}

    # preprocessing on the correlation bulk before stretch estimation
    preprocessing: [
                    {'function': 'smooth', 'args': {'wsize': 48, 'wtype': 'hanning', 'axis': 1}}
    ]

    ### SAVING
    # save components separately or only their average?
    save_comps: False

