{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SeisMIC** Tutorial\n",
    "\n",
    "![](./seismic_logo.png)\n",
    "\n",
    "In the following, we will go through a simple example to compute a ambient noise correlations and monitor velocity changes using **SeisMIC**.\n",
    "\n",
    "The source code is hosted here: [SeisMIC](https://github.com/PeterMakus/SeisMIC).\n",
    "\n",
    "The documentation, which this notebook is based upon is located here:\n",
    "[SeisMIC Documentation](https://petermakus.github.io/SeisMIC/).\n",
    "\n",
    "\n",
    "As an exercise, we will download data from one channel of the station `X9.IR1` to investigate the coseismic velocity change caused by the M7.2 2016 Zhupanov earthquake\n",
    "(see [Makus et. al., 2023](https://doi.org/10.1029/2022JB025738)).\n",
    "Without further ado, we'll dive right into it starting with data download.\n",
    "\n",
    "**Note that to execute this tutorial, you will have to install jupyter into your environment (e.g. via `pip install jupyer`).**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download the raw data\n",
    "**SeisMIC** uses [obspy](https://docs.obspy.org/) to download data from FDSN servers.\n",
    "\n",
    "To download the data, we will use the [`seismic.trace_data.waveform.Store_Client`](https://petermakus.github.io/SeisMIC/modules/API.html#seismic.trace_data.waveform.Store_Client) class and its method `download_waveforms_mdl()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy import UTCDateTime\n",
    "\n",
    "from seismic.trace_data.waveform import Store_Client\n",
    "\n",
    "# Get notebook path for future reference of the database:\n",
    "try: ipynb_path\n",
    "except NameError: ipynb_path = os.getcwd()\n",
    "\n",
    "os.chdir(ipynb_path)\n",
    "\n",
    "root = os.path.join(ipynb_path, 'data')\n",
    "os.makedirs(root, exist_ok=True)\n",
    "\n",
    "starttime = UTCDateTime(2016, 1, 25)\n",
    "endtime = UTCDateTime(2016, 2, 5)\n",
    "network = 'X9'\n",
    "station = 'IR1'\n",
    "\n",
    "\n",
    "c = Client('GEOFON')\n",
    "sc = Store_Client(c, root, read_only=False)\n",
    "sc.download_waveforms_mdl(\n",
    "    starttime, endtime, clients=[c], network=network,\n",
    "    station=station, location='*', channel='HHE')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some notes about this:\n",
    "1. The method `download_waveforms_mdl()` expects a list of clients as input.\n",
    "2. All arguments accept wildcards\n",
    "\n",
    "If everything worked fine. This should have created a folder called `data/mseed` and `data/inventory`. Let's check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('./data/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Plot a time-dependent spectrogram\n",
    "\n",
    "A good first step to evaluate how the noise looks in the different frequency bands is by plotting a spectral series. SeisMIC possesses an efficient implentation using Welch windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seismic.plot.plot_spectrum import plot_spct_series\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "f, t, S = sc.compute_spectrogram('X9', 'IR1', 'HHE', starttime, endtime, 7200, freq_max=12.5)\n",
    "fig = plt.figure(figsize=(9, 7))\n",
    "plot_spct_series(S, f, t, log_scale=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute Correlations\n",
    "That seems to have worked, so we are ready to use this raw data to compute ambient noise correlations.\n",
    "\n",
    "### 2.1 Parameters\n",
    "Parameters are provided as a `yaml` file or a `dict` object. This tutorial comes with an yaml file to process the data. Let's have a short look at it using bash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat params.yaml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the parameters is described in the [Documentation](https://petermakus.github.io/SeisMIC/modules/correlate/get_started.html).\n",
    "\n",
    "To start the computation of the correlation we will use [`MPI`](https://mpi4py.readthedocs.io/) and a simple python script, which could look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat correlate.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Start correlation\n",
    "To start the correlation, we will use the `mpirun` command in bash:\n",
    "\n",
    "Jupyter notebook limits the output, so if you wish to see the complete output, you might prefer actually executing these commands in a terminal. Sometimes this might even be required - depending on your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# This gives number of threads, usually twice as many as physical cores\n",
    "ncpus = os.cpu_count()//2\n",
    "\n",
    "# note that mpi commands might have to be launched from the command line\n",
    "# (depeding on your system)\n",
    "!mpirun -n $ncpus python correlate.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's have a look at those correlations. To do so, we use the [`CorrelationDataBase`](https://petermakus.github.io/SeisMIC/modules/API.html#seismic.db.corr_hdf5.CorrelationDataBase) object.\n",
    "All correlations are saved in the folder `data/corr` as defined in our params.yaml file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seismic.db.corr_hdf5 import CorrelationDataBase\n",
    "\n",
    "with CorrelationDataBase(f'data/corr/{network}-{network}.{station}-{station}.HHE-HHE.h5', mode='r') as cdb:\n",
    "    # find the available labels\n",
    "    print(list(cdb.keys()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SeisMIC's** standard labels are `'subdivision` for the correlations of corr_len and `stack_*stacklen*` for the stack (with *stacklen* being the length of the stack in seconds).\n",
    "\n",
    "**SeisMIC** uses some sort of \"combined seed codes\" structured as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with CorrelationDataBase(f'data/corr/{network}-{network}.{station}-{station}.HHE-HHE.h5', mode='r') as cdb:\n",
    "    # find the available labels\n",
    "    print(cdb.get_available_channels(\n",
    "        tag='stack_86398', network=f'{network}-{network}', station=f'{station}-{station}'))\n",
    "    print(cdb.get_available_starttimes(\n",
    "        tag='subdivision', network=f'{network}-{network}', station=f'{station}-{station}', channel='*'))\n",
    "    cst = cdb.get_data(f'{network}-{network}', f'{station}-{station}', 'HHE-HHE', 'subdivision')\n",
    "print(type(cst))\n",
    "\n",
    "# filter frequencies, so we can see something\n",
    "cst = cst.filter('bandpass', freqmin=2, freqmax=4, zerophase=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cst` is now a [`CorrStream`](https://petermakus.github.io/SeisMIC/modules/API.html#seismic.correlate.stream.CorrStream) - an obspy based object to handle correlations. We can plot those in a section plot for example by time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "ax0 = plt.subplot(2, 1, 1)\n",
    "\n",
    "cst.plot(timelimits=[-20, 20], cmap='seismic', vmin=-0.5, vmax=0.5, ax=ax0)\n",
    "ax0.set_title(f'Autocorrelation {network}.{station}.HHE')\n",
    "ax1 = plt.subplot(2, 1, 2)\n",
    "cst.plot(scalingfactor=3, timelimits=[0, 20], type='section', ax=ax1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look very very closely, you can see a slight time shift in the late coda on January 30th. This time shift is associated to the Zhupanov earthquake. We will try to quantify the velocity change in the following.\n",
    "\n",
    "We can also look at a single correlations or at a stack of correlations. SeisMIC can stack correlation with `CorrStream.stack`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrstack = cst.stack()[0]\n",
    "corrstack.plot(tlim=[-20,20])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try and combine the two last plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 10))\n",
    "ax0 = plt.subplot(2, 1, 1)\n",
    "\n",
    "cst.plot(timelimits=[-20, 20], cmap='seismic', vmin=-0.5, vmax=0.5, ax=ax0)\n",
    "ax0.set_title(f'(a)')\n",
    "ax0.plot(\n",
    "    corrstack.times(),\n",
    "    [UTCDateTime(i).datetime for i in corrstack.data*3e5 +  UTCDateTime(2016, 1, 31).timestamp],\n",
    "    color='k', zorder=100, linewidth=1.1)\n",
    "\n",
    "ax1 = plt.subplot(2, 1, 2)\n",
    "cst.plot(scalingfactor=3, timelimits=[0, 20], type='section', ax=ax1)\n",
    "ax1.set_title(f'(b)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Waveform Coherence\n",
    "\n",
    "We can assess the average stability of the wavefield in different frequency\n",
    "bands and along the lapse time axis using a measure called the waveform coherence\n",
    "(see ,e.g., Steinmann, et al., 2021).\n",
    "The waveform coherence is the zero lag correlation of two noise correlations.\n",
    "Here we average them for one station and given frequency and lapse time bands.\n",
    "\n",
    "For this step, we will have to compute a few more noise correlations over various\n",
    "frequency bands. That's why the next cell will take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python wfc.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seismic.monitor.wfc import WFCBulk\n",
    "from seismic.monitor.wfc import read_wfc\n",
    "\n",
    "wfcs = read_wfc('data/wfc/WFC-X9-X9.IR1-IR1.av.*.npz')\n",
    "WFCBulk(wfcs).plot(log=True, cmap='batlow')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Monitoring\n",
    "\n",
    "Next, we will compute a velocity change estimate using the stretching technique ([Sens-Schönfelder & Wegler, 2006](https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2006gl027797)).\n",
    "You can find the corresponding parameters in the `dv` section of the `params.yaml` file.\n",
    "\n",
    "Similarly to the Correlation we can start the monitoring via a simple script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat monitor.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: ipynb_path\n",
    "except NameError: ipynb_path = os.getcwd()\n",
    "\n",
    "os.chdir(ipynb_path)\n",
    "\n",
    "# multi-core is not necessarily useful for this example\n",
    "# because the jobs are split into N jobs, where N is the number of\n",
    "# component combinations (in our case N==1)\n",
    "ncpus = os.cpu_count()//2\n",
    "\n",
    "# note that mpi commands might have to be launched from the command line\n",
    "# (depeding on your system)\n",
    "!mpirun -n $ncpus python ./monitor.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a first plot to get an idea of *dv/v*\n",
    "We can use SeisMIC's inbuilt plotting function for that. The velocity changes will in general be shown in decimal values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seismic.monitor.dv import read_dv\n",
    "dv = read_dv(f'data/vel_change/DV-{network}-{network}.{station}-{station}.HHE-HHE.npz')\n",
    "dv.plot(ylim=(-0.01,0.01))\n",
    "\n",
    "# We can print some information about the dv object\n",
    "print(dv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with comparably little data, we can see the velocity drop on January 30th. Note that due to the high energy noise, we are able to retrieve a very high resolution estimate of *dv/v*."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the plot look a little nicer\n",
    "The plot above is very good if you just want to understand what is going on, but maybe it is not necessarily something you would want to put into a publication. Here is a code that makes the plot look like in the above mentioned publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import UTCDateTime\n",
    "\n",
    "from seismic.plot.plot_utils import set_mpl_params\n",
    "\n",
    "set_mpl_params()\n",
    "\n",
    "# Origin Time of the Zhupanov earthquake\n",
    "otime = UTCDateTime(2016, 1, 30, 3, 25).datetime\n",
    "\n",
    "fig, ax = dv.plot(style='publication', return_ax=True, ylim=(-.75,.75),\n",
    "                  dateformat='%d %b')\n",
    "\n",
    "plt.axvline(otime, linestyle='dashed', c='r', label='M7.2')\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What comes next?\n",
    "\n",
    "## Increasing the stability\n",
    "\n",
    "In this case, we are fortunate enough to receive a high-resolution `dv/v` estimate with the given parameters (not quite by coincidence ;-)).\n",
    "\n",
    "For many other datasets, you might not be able to achieve satisfactory stability.\n",
    "Here are some suggestions on how you could tackle that:\n",
    "1. Increase the smoothing. This can be done over a number of different ways, all of them can be configured in `params.yaml`:\n",
    "    - increase `dv['win_len']` to stack correlations over the defined amount of time (in seconds)\n",
    "    - in `dv['preprocessing']` increase the parameter `wsize` of the `smooth` function to smoooth the correlation functions over a larger amount of time (see [documentation](https://petermakus.github.io/SeisMIC/modules/API.html#seismic.correlate.stream.CorrBulk.smooth))\n",
    "    - In `dv['postprocessing']` set a smoothing of the similarity matrix (see [documentation](https://petermakus.github.io/SeisMIC/modules/API.html#seismic.monitor.dv.DV.smooth_sim_mat))\n",
    "2. Try different frequencies, different lag time windows of the coda or a different preprocessing.\n",
    "3. Stack the results from several component combinations as done in [Illien et al. 2023](https://academic.oup.com/gji/article-abstract/234/1/124/7008901). The corresponding function in Seismic is in [seismic.monitor.monitor.average_component_combinations()](https://petermakus.github.io/SeisMIC/modules/API.html#seismic.monitor.monitor.average_components)\n",
    "\n",
    "## Explore other processing possibilities\n",
    "There are a large number of flavours for different processing options explored. Some of which are natively shipped in SeisMIC. You can experiment with options to processing your noise correlation functions differently or compute *dv/v* differently (e.g., thinking about other algorithms than the stretching technique). By the way: the dictionaries in the different processing parameters in `params.yaml` allow to import external functions as long as they are scripted in the right way (see link).\n",
    "\n",
    "## Invert for a velocity change map\n",
    "The module `seismic.monitor.spatial` implements the surface wave spatial inversion as proposed by [Obermann et al. (2013)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/2013JB010399). Consult the documentation, to learn how to work with spatial inversions. You can continue with the [spatial Jupyter Notebook](./spatial.ipynb) to learn how to do a spatial inversion with SeisMIC."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "List of references used in this notebook.\n",
    "\n",
    "[Illien, Luc, Christoph Sens-Schönfelder, and Kuan-Yu Ke. \"Resolving minute temporal seismic velocity changes induced by earthquake damage: the more stations, the merrier?.\" Geophysical Journal International 234.1 (2023): 124-135.](https://doi.org/10.1093/gji/ggad038)\n",
    "\n",
    "[Makus, P., Sens-Schönfelder, C., Illien, L., Walter, T. R., Yates, A., & Tilmann, F. (2023). Deciphering the whisper of volcanoes: Monitoring velocity changes at Kamchatka's Klyuchevskoy group with fluctuating noise fields. Journal of Geophysical Research: Solid Earth, 128, e2022JB025738.](https://doi.org/10.1029/2022JB025738)\n",
    "\n",
    "[Obermann, A., Planès, T., Larose, E., and Campillo, M. (2013), Imaging preeruptive and coeruptive structural and mechanical changes of a volcano with ambient seismic noise, J. Geophys. Res. Solid Earth, 118, 6285– 6294.](https://doi.org/10.1002/2013JB010399)\n",
    "\n",
    "[Steinmann, R., Hadziioannou, C., & Larose, E. (2020). Effect of centimetric freezing of the near subsurface on Rayleigh and Love wave velocity in ambient seismic noise correlations. Geophysical Journal International, 224(1), 626-636.](https://doi.org/10.1093/gji/ggaa406)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download this notebook\n",
    "You can download this notebook on our [GitHub page](https://github.com/PeterMakus/SeisMIC/blob/main/examples/)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
